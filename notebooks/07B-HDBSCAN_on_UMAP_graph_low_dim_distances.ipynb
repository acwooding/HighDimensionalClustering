{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e429df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Persistent single-linkage (HDBSCAN) clustering on sparse matrices\n",
    "\n",
    "This is our attempt at running an HDBSCAN approach (persistent single linkage) on a sparse distance matrix. \n",
    "The sparse distance matrix we use here is the UMAP matrix with distances coming from the low dimensional projection from UMAP. We want to see how the code behaves on a partial distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4875757-c802-423c-8bf8-8efd45ff78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mmaster\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d3bdf4-9b88-4008-93e6-5e6f656e5b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pendigits', 'coil', 'mnist', 'usps', 'buildings', 'clusterable']\n"
     ]
    }
   ],
   "source": [
    "execfile('functions/data_specifics.py')\n",
    "execfile('functions/graph_functions.py')\n",
    "print(data_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from sklearn import cluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import umap\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7941f209-c136-4981-8066-31a64b6e2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import scipy.sparse\n",
    "import sklearn.cluster\n",
    "from hdbscan._hdbscan_tree import (\n",
    "    condense_tree,\n",
    "    compute_stability,\n",
    "    get_clusters,\n",
    "    outlier_scores,\n",
    ")\n",
    "from hdbscan.plots import CondensedTree, SingleLinkageTree, MinimumSpanningTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26877179-761c-423a-8588-cdcd30adb10a",
   "metadata": {},
   "source": [
    "## Get clusters from a (disconnected) sparse distance matrix\n",
    "\n",
    "* The 0-values indicate \"far away\" points\n",
    "\n",
    "If the matrix has disconnected components (when viewed as a graph), HDBSCAN does not work. To get around this, we have tried clustering each component separately or just adding edges to glue the different parts together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1448e9-2e0c-4120-93e4-cce1acdad897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_from_sparse(D,\n",
    "                       connected_component_method = 'glue', # 'glue' or 'individual'\n",
    "                       cluster_selection_method = 'eom',\n",
    "                       allow_single_cluster=False,\n",
    "                       cluster_selection_epsilon=0.0,\n",
    "                       max_cluster_size=0,\n",
    "                       min_cluster_size=10,\n",
    "                       no_split_size = 100,\n",
    "                       alpha = 1.2):\n",
    "    par = locals()\n",
    "\n",
    "    cc = scipy.sparse.csgraph.connected_components(D)\n",
    "    n = D.shape[0]\n",
    "\n",
    "    if(cc[0] == 1):\n",
    "        labels = clustering_from_sparse_connected(**par)\n",
    "        \n",
    "    elif (connected_component_method == 'glue'):\n",
    "        print(\"Disconnected distance matrix: \\n -Connecting distance matrix\")\n",
    "        labels = clustering_from_sparse_force_connection(**par)\n",
    "        \n",
    "    elif( connected_component_method == 'individual' ):\n",
    "        print(\"Disconnected distance matrix: \\n -Performing clustering on individual connected components\")\n",
    "        labels = clustering_from_sparse_on_individual_cc(**par)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Parameter should be glue or individual')\n",
    "        \n",
    "    return(labels)\n",
    "\n",
    "\n",
    "# Single linkage on sparse matrix when the initial distance matrix is connected.\n",
    "def clustering_from_sparse_connected(D,\n",
    "                       connected_component_method = 'glue',\n",
    "                       cluster_selection_method = 'eom',\n",
    "                       allow_single_cluster=False,\n",
    "                       cluster_selection_epsilon=0.0,\n",
    "                       max_cluster_size=0,\n",
    "                       min_cluster_size=10,\n",
    "                       no_split_size = 100,\n",
    "                       alpha = 1.2):\n",
    "    \n",
    "    mst = scipy.sparse.csgraph.minimum_spanning_tree(D)\n",
    "    mst = mst.tocoo()\n",
    "    mst_array = np.vstack([mst.row, mst.col, mst.data]).T\n",
    "    \n",
    "    # Sort edges of the min_spanning_tree by weight\n",
    "    mst_array = mst_array[np.argsort(mst_array.T[2], kind=\"mergesort\"), :]\n",
    "\n",
    "    # Convert edge list into standard hierarchical clustering format\n",
    "    single_linkage_tree = sklearn.cluster._hierarchical_fast._single_linkage_label(mst_array)\n",
    "    \n",
    "    ## HDBSCAN function\n",
    "    cd_tree = condense_tree(single_linkage_tree, min_cluster_size)\n",
    "    \n",
    "    ## HDBSCAN function\n",
    "    stability_dict = compute_stability(cd_tree)\n",
    "    \n",
    "    ## HDBSCAN function\n",
    "    labels, probabilities, stabilities = get_clusters(\n",
    "            cd_tree,\n",
    "            stability_dict,\n",
    "            cluster_selection_method = cluster_selection_method,\n",
    "            allow_single_cluster = allow_single_cluster,\n",
    "            cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "            max_cluster_size=max_cluster_size\n",
    "        )\n",
    "    return(labels)\n",
    "\n",
    "\n",
    "# Performing clustering on individual connected components of the sparse distance matrix\n",
    "def clustering_from_sparse_on_individual_cc(D,\n",
    "                       connected_component_method = 'glue',\n",
    "                       cluster_selection_method = 'eom',\n",
    "                       allow_single_cluster=False,\n",
    "                       cluster_selection_epsilon=0.0,\n",
    "                       max_cluster_size=0,\n",
    "                       min_cluster_size=10,\n",
    "                       no_split_size = 100,\n",
    "                       alpha = 1.2):\n",
    "    \n",
    "    # Check connected components\n",
    "    cc = scipy.sparse.csgraph.connected_components(D)\n",
    "    n = D.shape[0]\n",
    "    \n",
    "    if(cc[0]==1):\n",
    "        labels = clustering_from_sparse_connected(D)\n",
    "    else:\n",
    "        labels = np.array([-1]*n)\n",
    "        for comp in range(cc[0]):\n",
    "            w = (cc[1]==comp)\n",
    "            m = sum(w)\n",
    "            if(m < min_cluster_size):\n",
    "                continue\n",
    "            elif(m < no_split_size):\n",
    "                labels_part = np.zeros(m)\n",
    "            else:\n",
    "                D_part = D[w, :][:, w]\n",
    "                labels_part = clustering_from_sparse_connected(D_part,\n",
    "                                                            cluster_selection_method = cluster_selection_method,\n",
    "                                                            allow_single_cluster = allow_single_cluster,\n",
    "                                                            cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "                                                            max_cluster_size=max_cluster_size,\n",
    "                                                            min_cluster_size=min_cluster_size)\n",
    "                if(sum(labels_part==-1)>(len(labels_part)/2)):\n",
    "                    labels_part = 0*labels_part\n",
    "            w[w] = (labels_part>=0)\n",
    "            labels[w] = (labels_part[labels_part>=0] + max(labels) + 1)\n",
    "    return(labels)\n",
    "\n",
    "\n",
    "# Adding large distance values (alpha * largest) to sparse distance matrix to make it connected\n",
    "def clustering_from_sparse_force_connection(D,\n",
    "                       connected_component_method = 'glue',\n",
    "                       cluster_selection_method = 'eom',\n",
    "                       allow_single_cluster=False,\n",
    "                       cluster_selection_epsilon=0.0,\n",
    "                       max_cluster_size=0,\n",
    "                       min_cluster_size=10,\n",
    "                       no_split_size = 100,\n",
    "                       alpha = 1.2):\n",
    "    \n",
    "    # Check connected components\n",
    "    cc = scipy.sparse.csgraph.connected_components(D)\n",
    "    cc_list = cc[1].tolist()\n",
    "    if(cc[0]>1): # Add edges to connect if more than one connected component\n",
    "        m = max(D.data)\n",
    " \n",
    "        rows = []\n",
    "        cols = []\n",
    "        vals = []\n",
    "        for i in set(cc[1]):\n",
    "            for j in set(cc[1]):\n",
    "                if(i>j):\n",
    "                    new_i = cc_list.index(i)\n",
    "                    new_j = cc_list.index(j)\n",
    "                    rows.extend([new_i, new_j])\n",
    "                    cols.extend([new_j, new_i])\n",
    "                    vals.extend([alpha*m, alpha*m])\n",
    "        D_glue = scipy.sparse.coo_matrix((vals, (rows, cols)), shape=D.shape)\n",
    "        D_new = D + D_glue\n",
    "    else:\n",
    "        D_new = D\n",
    "                       \n",
    "    labels = clustering_from_sparse_connected(D_new)\n",
    "    return(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d169fe-f792-44f3-804f-2491582d49d1",
   "metadata": {},
   "source": [
    "# Clustering algorithm\n",
    "These are the steps we use to feed a sparse distance matrix to the single linkage...\n",
    "We are not using HDBSCAN at the moment, but this is where we would like to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e0edb-43b9-4afe-8d0f-01b21faf3004",
   "metadata": {},
   "source": [
    "## Get data, UMAP graph and UMAP low dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87352309-e8d9-4c70-97ac-175132259798",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id=0\n",
    "raw_data, targets, dataset_name = get_dataset(dataset_id=dataset_id)\n",
    "\n",
    "k = get_dataset_params(dataset_id)['n_neighbors']\n",
    "\n",
    "A_umap, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data, \n",
    "                                             n_neighbors=k, \n",
    "                                             random_state=0, \n",
    "                                             metric='euclidean', \n",
    "                                             return_dists=True,\n",
    "                                             set_op_mix_ratio=1)\n",
    "\n",
    "umap_rep = get_umap_vectors(dataset_id=dataset_id, raw_data=raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079000e5-3584-492d-b928-de4ae7d1aa47",
   "metadata": {},
   "source": [
    "## Build the partial distance matrix based of UMAP graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e1faf25-52a6-4e3e-9926-7822edf3edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = A_umap.copy()\n",
    "rows = [x for v in [[i]*v for i, v in enumerate(A_umap.indptr[1:] - A_umap.indptr[:-1])] for x in v]\n",
    "D.data = np.array([euclidean( umap_rep[rows[i]], \n",
    "                                         umap_rep[A_umap.indices[i]])\n",
    "            for i in range(len(rows))\n",
    "           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dd5d2-073d-43b4-86c6-c3ac0aedc604",
   "metadata": {},
   "source": [
    "## Compare robust single-linkage (portions of HDBSCAN) on partial distance vs. on low dim projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1fbcbe3-fce2-4dff-8522-6ed482fd322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI = 0.5937845136423342 and AMI = 0.7459900925803741\n"
     ]
    }
   ],
   "source": [
    "labels = clustering_from_sparse(D)\n",
    "\n",
    "ari = adjusted_rand_score(targets, labels)\n",
    "ami = adjusted_mutual_info_score(targets, labels)\n",
    "print(f'ARI = {ari} and AMI = {ami}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10595951-da7e-4bf2-a6b0-639ed26b65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI = 0.9185149200427103 and AMI = 0.9320899303214291\n"
     ]
    }
   ],
   "source": [
    "hd_umap_labels = h_dbscan(umap_rep, which_algo='hdbscan', dataset_id=dataset_id)\n",
    "\n",
    "ari = adjusted_rand_score(targets, hd_umap_labels)\n",
    "ami = adjusted_mutual_info_score(targets, hd_umap_labels)\n",
    "print(f'ARI = {ari} and AMI = {ami}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60213c5a-dbee-4812-86a9-d4e373cba030",
   "metadata": {},
   "source": [
    "# Run on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4423fa32-dfd4-487e-b3eb-8a8c2de9c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_linkage_clustering(dataset_id, distance_function, k=None):\n",
    "    raw_data, targets, dataset_name = get_dataset(dataset_id=dataset_id)\n",
    "    display(Markdown(f'### {dataset_name}'))\n",
    "    \n",
    "    if(distance_function.__name__ == \"get_avg_neighbor_distance\"):\n",
    "        D = distance_function(raw_data)\n",
    "    else:\n",
    "        if(k is None):\n",
    "            k = get_dataset_params(dataset_id)['n_neighbors']\n",
    "\n",
    "        A_umap, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data, \n",
    "                                                         n_neighbors=k, \n",
    "                                                         random_state=0, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                         set_op_mix_ratio=0.5)\n",
    "        umap_rep = get_umap_vectors(dataset_id=dataset_id, raw_data=raw_data)\n",
    "        D = distance_function(A_umap, umap_rep)\n",
    "\n",
    "    labels = clustering_from_sparse(D)\n",
    "\n",
    "    ari = adjusted_rand_score(targets, labels)\n",
    "    ami = adjusted_mutual_info_score(targets, labels)\n",
    "    print(f'PARTIAL DISTANCE:\\nARI = {ari} and AMI = {ami}\\n')\n",
    "    \n",
    "    hd_umap_labels = h_dbscan(umap_rep, which_algo='hdbscan', dataset_id=dataset_id)\n",
    "\n",
    "    ari = adjusted_rand_score(targets, hd_umap_labels)\n",
    "    ami = adjusted_mutual_info_score(targets, hd_umap_labels)\n",
    "    print(f'UMAP+HDBSCAN:\\nARI = {ari} and AMI = {ami}\\n\\n')\n",
    "    \n",
    "    return(labels, ari, ami, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0962c2be-5641-44ef-88b6-6d9ecac140e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_dim_distance(A_umap, umap_rep):\n",
    "    D = A_umap.copy()\n",
    "    rows = [x for v in [[i]*v for i, v in enumerate(A_umap.indptr[1:] - A_umap.indptr[:-1])] for x in v]\n",
    "    D.data = np.array([euclidean( umap_rep[rows[i]], \n",
    "                                             umap_rep[A_umap.indices[i]])\n",
    "                for i in range(len(rows))\n",
    "               ])\n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e416da9-5460-41fc-bc14-86da2b25f4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### pendigits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL DISTANCE:\n",
      "ARI = 0.5937845136423342 and AMI = 0.7459900925803741\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.9185149200427103 and AMI = 0.9320899303214291\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### coil"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/home/vmpouli/.conda/envs/high-dim-easydata/lib/python3.7/site-packages/sklearn/manifold/_spectral_embedding.py:261: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  \"Graph is not fully connected, spectral embedding may not work as expected.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disconnected distance matrix: \n",
      " -Connecting distance matrix\n",
      "PARTIAL DISTANCE:\n",
      "ARI = 0.7366539128552851 and AMI = 0.8614787111461784\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.7910813366998825 and AMI = 0.9424028955749346\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### mnist"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL DISTANCE:\n",
      "ARI = 0.6536270135409726 and AMI = 0.6850632024244153\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.8987078065717921 and AMI = 0.8868226537248037\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### usps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL DISTANCE:\n",
      "ARI = 0.7406192640111551 and AMI = 0.7621950198047123\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.8824676944734986 and AMI = 0.9004545663772475\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### buildings"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disconnected distance matrix: \n",
      " -Connecting distance matrix\n",
      "PARTIAL DISTANCE:\n",
      "ARI = 0.162062153104807 and AMI = 0.5937277651507081\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.2458851298996959 and AMI = 0.6307848503576966\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### clusterable"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL DISTANCE:\n",
      "ARI = 0.09585077605431681 and AMI = 0.4880254512377565\n",
      "\n",
      "UMAP+HDBSCAN:\n",
      "ARI = 0.1478619673703955 and AMI = 0.5132842384271498\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    res = get_single_linkage_clustering(dataset_id=i, distance_function = low_dim_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a91be-8973-43c5-b1bb-93c2294ef226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "high-dim-easydata",
   "language": "python",
   "name": "high-dim-easydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
