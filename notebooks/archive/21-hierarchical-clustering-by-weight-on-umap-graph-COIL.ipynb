{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e429df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Attempt to use hierarchical clustering on the weighted UMAP graph directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3bdf4-9b88-4008-93e6-5e6f656e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile('functions/data_specifics.py')\n",
    "execfile('functions/graph_functions.py')\n",
    "print(data_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from sklearn import cluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575767a-2d03-4f6c-a39d-9553cdc465c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.sparse.csgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e0edb-43b9-4afe-8d0f-01b21faf3004",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352309-e8d9-4c70-97ac-175132259798",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id=1\n",
    "raw_data, targets, dataset_name = get_dataset(dataset_id=dataset_id)\n",
    "\n",
    "k = get_dataset_params(dataset_id)['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caab6b5",
   "metadata": {},
   "source": [
    "## UMAP Graph\n",
    "\n",
    "Build and visualize the UMAP graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5c7ba-971d-4953-97c4-39e37a6a09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne_map = TSNE().fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_graph, _, _ = umap.umap_.fuzzy_simplicial_set(raw_data, n_neighbors=15, metric=\"euclidean\", random_state=42)\n",
    "umap_graph = symmetric_graph.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e81fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "coo_umap_graph = umap_graph.tocoo()\n",
    "edges = LineCollection(\n",
    "    np.dstack([tsne_map[coo_umap_graph.row], tsne_map[coo_umap_graph.col]]).transpose((0, 2, 1)), \n",
    "    linewidths=0.5 * coo_umap_graph.data, \n",
    "    colors=np.vstack([np.zeros((3, coo_umap_graph.data.shape[0])), coo_umap_graph.data]).T,\n",
    "    zorder=3\n",
    ")\n",
    "ax.add_collection(edges)\n",
    "ax.scatter(*tsne_map.T, s=5, c=targets, cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a7bca",
   "metadata": {},
   "source": [
    "# Modified Girvan-Newman to find when connected components break\n",
    "\n",
    "This is effectively a divisive hierarchical clustering algorithm. We remove the edges of the umap graph from lowest weight to highest weight, and each time we break a connected component into more parts, we get a new list of communities. `nx.community.girvan_newman(umap_G, most_valuable_edge=lowest_weight)` returns a list of flat cuts, each level of the hierarchical clustering where a new component was introduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d016a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_G = nx.from_scipy_sparse_matrix(umap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a552e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_weight(G):\n",
    "    u, v, w = min(G.edges(data='weight'), key=itemgetter(2))\n",
    "    return (u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "communities = list(nx.community.girvan_newman(umap_G, most_valuable_edge=lowest_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b77049",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_communities = communities.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e3e13",
   "metadata": {},
   "source": [
    "Let's look at the modularity of the various cut levels (from the example here: https://networkx.org/documentation/stable/auto_examples/algorithms/plot_girvan_newman.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Modularity -> measures the strength of division of a network into modules\n",
    "modularity_df = pd.DataFrame(\n",
    "    [\n",
    "        [k + 1, len(communities[k]), nx.community.modularity(umap_G, communities[k])]\n",
    "        for k in range(len(communities))\n",
    "    ],\n",
    "    columns=[\"cut level\", \"components\", \"modularity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7242a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity_df[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e72c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mod = np.where(modularity_df.modularity==modularity_df.modularity.max())[0][0]\n",
    "modularity_df.iloc[max_mod]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed5992",
   "metadata": {},
   "source": [
    "This seems to be consistent with how we tend to get around 16 clusters using modularity based clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot change in modularity as the important edges are removed\n",
    "modularity_df.plot(x='cut level', y='modularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b5b2a",
   "metadata": {},
   "source": [
    "## Do flat cuts and evaluate the resulting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e24468",
   "metadata": {},
   "source": [
    "Let's look at the clustering results for flat cuts from 10 to 30. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3ced2",
   "metadata": {},
   "source": [
    "Turn a list of communities into a cluster label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "cluster_label_dict = {}\n",
    "for cut_level in range(150):\n",
    "    cluster_dict = {}\n",
    "    for i, cluster in enumerate(communities[cut_level]):\n",
    "        for element in cluster:\n",
    "            cluster_dict[element] = i\n",
    "\n",
    "    cluster_labels = []\n",
    "    for x in list(umap_G.nodes): \n",
    "        cluster_labels.append(cluster_dict[x])\n",
    "    cluster_label_dict[cut_level] = cluster_labels\n",
    "    \n",
    "    ari = adjusted_rand_score(targets, cluster_labels)\n",
    "    ami = adjusted_mutual_info_score(targets, cluster_labels)\n",
    "    results[cut_level] = {'ARI': ari, 'AMI': ami, 'Clusters': len(set(cluster_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1962872",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df[10:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64444d41",
   "metadata": {},
   "source": [
    "## A look at the various cut levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3fd21",
   "metadata": {},
   "source": [
    "At cut level 12, we have the highest modularity, and too few clusters. We have 2 overly large clusters (size 286 and 144) and a single tiny cluster of size 2 (which probably should be considered noise eventually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eed9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_level = 12\n",
    "results_df.T[cut_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster_label_dict[cut_level], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27251949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "coo_umap_graph = umap_graph.tocoo()\n",
    "edges = LineCollection(\n",
    "    np.dstack([tsne_map[coo_umap_graph.row], tsne_map[coo_umap_graph.col]]).transpose((0, 2, 1)), \n",
    "    linewidths=0.2 * coo_umap_graph.data, \n",
    "    colors=np.vstack([np.zeros((3, coo_umap_graph.data.shape[0])), coo_umap_graph.data]).T,\n",
    "    zorder=3\n",
    ")\n",
    "ax.add_collection(edges)\n",
    "ax.scatter(*tsne_map.T, s=5, c=cluster_label_dict[cut_level], cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07725ced",
   "metadata": {},
   "source": [
    "For cut level 15, we have the correct number of clusters, but it has not split the big clusters, just overly split some of the correct clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_level = 16\n",
    "results_df.T[cut_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster_label_dict[cut_level], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ddfe5",
   "metadata": {},
   "source": [
    "It is not until cut levels 16, 17, 18 and 19 that the big clusters start to get broken apart. By 18, we have 3 tiny clusters of size < 5, which we should probably refuse to cluster. By 19, we have our highest AMI and ARI, which is comparable to UMAP+HDBSCAN results (below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70973f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_level = 19\n",
    "results_df.T[cut_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cluster_label_dict[cut_level], return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "coo_umap_graph = umap_graph.tocoo()\n",
    "edges = LineCollection(\n",
    "    np.dstack([tsne_map[coo_umap_graph.row], tsne_map[coo_umap_graph.col]]).transpose((0, 2, 1)), \n",
    "    linewidths=0.2 * coo_umap_graph.data, \n",
    "    colors=np.vstack([np.zeros((3, coo_umap_graph.data.shape[0])), coo_umap_graph.data]).T,\n",
    "    zorder=3\n",
    ")\n",
    "ax.add_collection(edges)\n",
    "ax.scatter(*tsne_map.T, s=5, c=cluster_label_dict[cut_level], cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69592873",
   "metadata": {},
   "source": [
    "It's not until level 55 that we start to the clusters break from two merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut_level in range(150):\n",
    "    _, counts = np.unique(cluster_label_dict[cut_level], return_counts=True)\n",
    "    if max(counts) <= 72*2:\n",
    "        print(f'cut_level: {cut_level} \\nlargest cluster size: {max(counts)}\\nclusters: {len(counts)}\\ncounts:{counts}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f88cc5",
   "metadata": {},
   "source": [
    "And it's not until cut level 118 that all the clusters are size 72 or less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f0a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut_level in range(150):\n",
    "    _, counts = np.unique(cluster_label_dict[cut_level], return_counts=True)\n",
    "    if max(counts) <= 72:\n",
    "        print(f'cut_level: {cut_level} \\nlargest cluster size: {max(counts)}\\nclusters: {len(counts)}\\ncounts:{counts}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ec872",
   "metadata": {},
   "source": [
    "This suggests that some of these oversized components are very persistent, and are connected by lots of higher weight edges making them hard to break apart. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dcc73-4050-45aa-ab1f-2a1b990f37d1",
   "metadata": {},
   "source": [
    "# Compare against UMAP+HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a9778-7ea0-43fc-8a77-d29f1533ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_rep = get_umap_vectors(dataset_id=dataset_id, raw_data=raw_data)\n",
    "hd_umap_labels = h_dbscan(umap_rep, which_algo='hdbscan', dataset_id=dataset_id)\n",
    "ari_baseline = adjusted_rand_score(targets, hd_umap_labels)\n",
    "ami_baseline = adjusted_mutual_info_score(targets, hd_umap_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4901792",
   "metadata": {},
   "outputs": [],
   "source": [
    "val, counts = np.unique(hd_umap_labels, return_counts=True)\n",
    "print(f'largest cluster size: {max(counts)}\\nclusters: {len(counts)}\\ncounts:{counts}')\n",
    "print(f'ARI = {ari_baseline} and AMI = {ami_baseline}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529cd532",
   "metadata": {},
   "source": [
    "Admittedly, UMAP+HDBSCAN also fails to separate these large hard to separate clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a7ca7",
   "metadata": {},
   "source": [
    "The cut level with as similar max cluster size as UMAP+HDBSCAN is 17, with a similar ARI and AMI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cda81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut_level in range(150):\n",
    "    _, counts = np.unique(cluster_label_dict[cut_level], return_counts=True)\n",
    "    if max(counts) <= 216:\n",
    "        print(f'cut_level: {cut_level} \\nlargest cluster size: {max(counts)}\\nclusters: {len(counts)}\\ncounts:{counts}')\n",
    "        break\n",
    "results_df.T[cut_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92cca0-1fa4-480f-862c-547299300ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "coo_umap_graph = umap_graph.tocoo()\n",
    "edges = LineCollection(\n",
    "    np.dstack([tsne_map[coo_umap_graph.row], tsne_map[coo_umap_graph.col]]).transpose((0, 2, 1)), \n",
    "    linewidths=0.5 * coo_umap_graph.data, \n",
    "    colors=np.vstack([np.zeros((3, coo_umap_graph.data.shape[0])), coo_umap_graph.data]).T,\n",
    "    zorder=3\n",
    ")\n",
    "ax.add_collection(edges)\n",
    "ax.scatter(*tsne_map.T, s=5, c=hd_umap_labels, cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ef4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HighDimensionalClustering] *",
   "language": "python",
   "name": "conda-env-HighDimensionalClustering-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
