{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e429df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vectorize using neighbor information?\n",
    "\n",
    "Use thisnotthat kernel.\n",
    "conda env update --file TNT/environment.yml --prune\n",
    "\n",
    "Did not pursue because HDBSCAN does not handle reading a sparse matrix as entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4875757-c802-423c-8bf8-8efd45ff78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mmain\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d3bdf4-9b88-4008-93e6-5e6f656e5b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pendigits', 'coil', 'mnist', 'usps', 'buildings', 'clusterable']\n"
     ]
    }
   ],
   "source": [
    "execfile('functions/data_specifics.py')\n",
    "execfile('functions/graph_functions.py')\n",
    "print(data_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import hdbscan\n",
    "import umap\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "import pynndescent\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1974fd90-86d1-454f-b63f-9e4024e4ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizers as vz\n",
    "from vectorizers import transformers as vzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e5cdf1-9139-4b9c-9598-8852cf7b68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clusters(cluster_labels0, true_labels, raw_data, cluster_method=\"None\", min_cluster_size=1):\n",
    "    cluster_labels = cluster_labels0.copy()\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    cluster_sizes, size_ids = np.histogram(cluster_labels, bins=unique_labels)\n",
    "    if np.any(cluster_sizes <= min_cluster_size): # Has singleton clusters -- call them noise\n",
    "        singleton_clusters = size_ids[:-1][cluster_sizes < min_cluster_size]\n",
    "        for c in singleton_clusters:\n",
    "            cluster_labels[cluster_labels == c] = -1\n",
    "    if (np.any(cluster_labels < 0)): # Has noise points\n",
    "        clustered_points = (cluster_labels >= 0)\n",
    "        ari = adjusted_rand_score(true_labels[clustered_points], cluster_labels[clustered_points])\n",
    "        ami = adjusted_mutual_info_score(true_labels[clustered_points], cluster_labels[clustered_points])\n",
    "        sil = silhouette_score(raw_data[clustered_points], cluster_labels[clustered_points])\n",
    "        pct_clustered = (np.sum(clustered_points) / cluster_labels.shape[0])\n",
    "        #print(f\"ARI: {ari:.4f}\\nAMI: {ami:.4f}\\nSilhouette: {sil:.4f}\\nPct clustered: {pct_clustered * 100:.2f}%\")\n",
    "    else:\n",
    "        ari = adjusted_rand_score(true_labels, cluster_labels)\n",
    "        ami = adjusted_mutual_info_score(true_labels, cluster_labels)\n",
    "        sil = silhouette_score(raw_data, cluster_labels)\n",
    "        #print(f\"ARI: {ari:.4f}\\nAMI: {ami:.4f}\\nSilhouette: {sil:.4f}\")\n",
    "        pct_clustered = 1.0\n",
    "    \n",
    "    return {\"Method\": cluster_method, \"ARI\": ari, \"AMI\": ami, \"Silhouette\": sil, \"Pct Clustered\": pct_clustered}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bd894",
   "metadata": {},
   "source": [
    "# Pendigits clustering scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e947e01-c98c-4e30-9caa-b78fcf078621",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 0\n",
    "raw_data, targets, dataset_name = get_dataset(dataset_id)\n",
    "\n",
    "A, sigmas, rhos, dists = get_umap_graph(raw_data, dataset_id=dataset_id, set_op_mix_ratio=1.0, return_only_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8bb540-3ba9-4e5c-95a9-d5122df50919",
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = 1*(A>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c0cb78-681c-4567-b6ae-48cff486a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thisnotthat as tnt\n",
    "import panel as pn\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6400cb6-cebf-4540-8640-f3c36ee20dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, 23, ..., -1, 17, -1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN().fit_predict(A0.toarray())\n",
    "clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec7d1c9-6a4a-47be-9711-24d51f80801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Method': 'None',\n",
       " 'ARI': 0.5962509239278841,\n",
       " 'AMI': 0.763499452387987,\n",
       " 'Silhouette': 0.19609363,\n",
       " 'Pct Clustered': 0.49081803005008345}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_clusters(clusterer, targets, raw_data, cluster_method=\"None\", min_cluster_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f615841-bc86-4215-9f09-1451498a4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_info = vzt.InformationWeightTransformer().fit_transform(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed984cb-36df-4406-9f41-9bae79a8ece2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, 18, ..., -1, 24, -1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer_info = hdbscan.HDBSCAN().fit_predict(A_info.toarray())\n",
    "clusterer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bab589e9-4648-4ed1-81f0-4ed99b6576aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Method': 'None',\n",
       " 'ARI': 0.627210091250614,\n",
       " 'AMI': 0.7880989790097518,\n",
       " 'Silhouette': 0.19868945,\n",
       " 'Pct Clustered': 0.5420144685587089}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_clusters(clusterer_info, targets, raw_data, cluster_method=\"None\", min_cluster_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc9e397-c4a4-40ba-98f0-79e0af0a4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_using_neighbors(dataset_id):\n",
    "    raw_data, targets, dataset_name = get_dataset(dataset_id)\n",
    "    A, sigmas, rhos, dists = get_umap_graph(raw_data, dataset_id=dataset_id, set_op_mix_ratio=1.0, return_only_matrix=True)\n",
    "    A0 = 1*(A>0)\n",
    "    A_info = vzt.InformationWeightTransformer().fit_transform(A0)\n",
    "    clusterer_info = hdbscan.HDBSCAN().fit_predict(A_info.toarray())\n",
    "    return(eval_clusters(clusterer_info, targets, raw_data, cluster_method=None, min_cluster_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b846f4-656d-48e1-a1a9-458f858cdeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/home/vmpouli/.conda/envs/tnt_env/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_set_list)):\n",
    "    res = cluster_using_neighbors(dataset_id=i)\n",
    "    res['Data set'] = data_set_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3abcb-090b-47d6-9f69-b6e775587835",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnt_env",
   "language": "python",
   "name": "tnt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
