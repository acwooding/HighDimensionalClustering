{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e429df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustering evaluation on high dimensional data\n",
    "\n",
    "The goal of this notebook is to provide a basic template walkthrough of obtaining and preparing a number of (simple) high dimensional datasets that can reasonably used to clustering evaluation. The datasets chosen have associated class labels that *should* be meaningful in terms of how the data clusters, and thus we can use label based clustering evaluation such as ARI and AMI to determine how well different clustering approaches are performing.\n",
    "\n",
    "The primary purpose of this notebook is to provide a set of baseline datasets that clustering algorithm developers can try their algorithms out on. Performing reasinably well on these datasets is a necessary but not sufficient condition of a good clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed84d6a-eeca-4f9f-afc1-cc11b131d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3bdf4-9b88-4008-93e6-5e6f656e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import paths\n",
    "data_folder = paths['data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import imageio\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import re\n",
    "import rarfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import hdbscan\n",
    "import umap\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "import pynndescent\n",
    "\n",
    "import networkx as nx\n",
    "import cdlib.algorithms as cd\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab73773",
   "metadata": {},
   "source": [
    "# MNIST, USPS and Pendigits are easy\n",
    "\n",
    "We can use the sklearn API to fetch data for the Pendigits, MNIST and USPS datasets.\n",
    "\n",
    "Of these datasets pendigits is the smallest, with only 1797 samples, and is only 64 dimensional. This makes a good first dataset to test things out on -- the dataset is small enough that practically anything should be able to run on this efficiently.\n",
    "\n",
    "USPS provides a slightly more challenging dataset, with almost 10,000 samples and 256 dimensions, but is still samall enough to be tractable for even naive clustering implementations.\n",
    "\n",
    "MNIST provides a good basic scaling test with 70,000 samples in 784 dimensions. In practice this is not a very large dataset compared to many that people want to cluster, although the dimensionality may provide some challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "mnist = fetch_openml(\"MNIST_784\")\n",
    "usps = fetch_openml(\"USPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc2443",
   "metadata": {},
   "source": [
    "# Buildings and COIL are harder\n",
    "\n",
    "The buildings and COIL-20 datasets provide some slightly more challenging image based problems, with more complex images to be dealt with. Both are still small in number of samples, so should be easily tractable. COIL *should* be relatively easy to cluster since the different classes should provide fairly tight and distinct clusters (being 72 images of the same object from different angles for each class). The buildings dataset, which has colour images from many angles and different lighting conditions, should be a much more challenging problem to cluster if using simple euclidean distance on the flattened vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752902f-6990-48f1-a609-4e406601c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_folder):\n",
    "    bashCommand = f\"mkdir {data_folder}\"\n",
    "    os.system(bashCommand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2c7ca",
   "metadata": {},
   "source": [
    "### COIL-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.isfile(data_folder / 'coil20.zip'):\n",
    "    results = requests.get('http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-20/coil-20-proc.zip')\n",
    "    with open(data_folder / 'coil20.zip', \"wb\") as code:\n",
    "        code.write(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_zip = zipfile.ZipFile(data_folder / 'coil20.zip')\n",
    "mylist = images_zip.namelist()\n",
    "r = re.compile(\".*\\.png$\")\n",
    "filelist = list(filter(r.match, mylist))\n",
    "images_zip.extractall(str(data_folder) + '/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492310b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coil_feature_vectors = []\n",
    "for filename in filelist:\n",
    "    im = imageio.imread(data_folder / filename)\n",
    "    coil_feature_vectors.append(im.flatten())\n",
    "coil_20_data = np.asarray(coil_feature_vectors)\n",
    "coil_20_target = pd.Series(filelist).str.extract(\"obj([0-9]+)\", expand=False).values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340778c",
   "metadata": {},
   "source": [
    "## Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder / 'buildings.rar'):\n",
    "    results = requests.get('http://eprints.lincoln.ac.uk/id/eprint/16079/1/dataset.rar')\n",
    "    with open(data_folder / 'buildings.rar', \"wb\") as code:\n",
    "        code.write(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder / 'sheffield_buildings/Dataset/Dataset/1/S1-01.jpeg'):\n",
    "    rf = rarfile.RarFile(f'{data_folder}/buildings.rar')\n",
    "    rf.extractall(f'{data_folder}/sheffield_buildings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_data = []\n",
    "buildings_target = []\n",
    "for i in range(1, 41):\n",
    "    directory = data_folder / f\"sheffield_buildings/Dataset/Dataset/{i}\"\n",
    "    images = np.vstack([np.asarray(Image.open(filename).resize((96, 96))).flatten() for filename in glob(f\"{directory}/*\")])\n",
    "    labels = np.full(len(glob(f\"{directory}/*\")), i, dtype=np.int32)\n",
    "    buildings_data.append(images)\n",
    "    buildings_target.append(labels)\n",
    "buildings_data = np.vstack(buildings_data)\n",
    "buildings_target = np.hstack(buildings_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db372ef7",
   "metadata": {},
   "source": [
    "# Clustering metric eval\n",
    "\n",
    "To make things easier later we will write some short functions to evaluate clusterings (with some special handling of singleton clusters or noise points for clusterign algorithms that support such things), and to plot the results for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clusters(cluster_labels, true_labels, raw_data, cluster_method=\"None\", min_cluster_size=5):\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    cluster_sizes, size_ids = np.histogram(cluster_labels, bins=unique_labels)\n",
    "    if np.any(cluster_sizes == 1): # Has singleton clusters -- call them noise\n",
    "        singleton_clusters = size_ids[:-1][cluster_sizes <= min_cluster_size]\n",
    "        for c in singleton_clusters:\n",
    "            cluster_labels[cluster_labels == c] = -1\n",
    "    if np.any(cluster_labels < 0): # Has noise points\n",
    "        clustered_points = (cluster_labels >= 0)\n",
    "        ari = adjusted_rand_score(true_labels[clustered_points], cluster_labels[clustered_points])\n",
    "        ami = adjusted_mutual_info_score(true_labels[clustered_points], cluster_labels[clustered_points])\n",
    "        sil = silhouette_score(raw_data[clustered_points], cluster_labels[clustered_points])\n",
    "        pct_clustered = (np.sum(clustered_points) / cluster_labels.shape[0])\n",
    "        print(f\"ARI: {ari:.4f}\\nAMI: {ami:.4f}\\nSilhouette: {sil:.4f}\\nPct clustered: {pct_clustered * 100:.2f}%\")\n",
    "    else:\n",
    "        ari = adjusted_rand_score(true_labels, cluster_labels)\n",
    "        ami = adjusted_mutual_info_score(true_labels, cluster_labels)\n",
    "        sil = silhouette_score(raw_data, cluster_labels)\n",
    "        print(f\"ARI: {ari:.4f}\\nAMI: {ami:.4f}\\nSilhouette: {sil:.4f}\")\n",
    "        pct_clustered = 1.0\n",
    "    \n",
    "    return {\"Method\": cluster_method, \"ARI\": ari, \"AMI\": ami, \"Silhouette\": sil, \"Pct Clustered\": pct_clustered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a555f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(results_dataframe, score_types=(\"ARI\", \"AMI\"), colors=list(sns.color_palette()), width=0.75):\n",
    "    fig, axs = plt.subplots(1, len(score_types), figsize=(8 * len(score_types), 8))\n",
    "    x_ticklabels = results_dataframe.Method.unique()\n",
    "    x_positions = np.arange(len(x_ticklabels), dtype=np.float32) - width / 2\n",
    "    dim_red_types = results_dataframe[\"Dim Reduction\"].unique()\n",
    "    bar_width = width / len(dim_red_types)\n",
    "    for offset_idx, dim_red in enumerate(dim_red_types):\n",
    "        color = colors[offset_idx]\n",
    "        for i, score_type in enumerate(score_types):\n",
    "            sub_dataframe = results_dataframe[\n",
    "                (results_dataframe[\"Score Type\"] == score_type) &\n",
    "                (results_dataframe[\"Dim Reduction\"] == dim_red)\n",
    "            ]\n",
    "            axs[i].bar(\n",
    "                x=x_positions,\n",
    "                height=sub_dataframe[\"Score\"],\n",
    "                width=bar_width,\n",
    "                align=\"edge\",\n",
    "                color=[(*color, v) for v in sub_dataframe[\"Pct Clustered\"]],\n",
    "                label=dim_red if i ==0 else None,\n",
    "            )\n",
    "            axs[i].set_xlabel(\"Cluster Method\")\n",
    "            axs[i].set_xticks(np.arange(len(x_ticklabels)))\n",
    "            axs[i].set_xticklabels(x_ticklabels)\n",
    "            axs[i].set_ylabel(f\"{score_type} Score\")\n",
    "            axs[i].set_title(score_type, fontsize=20)\n",
    "            axs[i].grid(visible=False, axis=\"x\")\n",
    "            axs[i].set_ylim([0, 1.05])\n",
    "        x_positions += bar_width\n",
    "        \n",
    "    if len(dim_red_types) > 1:\n",
    "        fig.legend(loc=\"center right\", bbox_to_anchor=(1.125, 0.5), borderaxespad=0.0, fontsize=20)\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bd894",
   "metadata": {},
   "source": [
    "# Pendigits clustering scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pendigits = digits.data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44678502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_labels = cluster.KMeans(n_clusters=10).fit_predict(raw_pendigits)\n",
    "cl_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(raw_pendigits)\n",
    "sl_labels = cluster.AgglomerativeClustering(n_clusters=160, linkage=\"single\").fit_predict(raw_pendigits)\n",
    "db_labels = cluster.DBSCAN(eps=20.0).fit_predict(raw_pendigits)\n",
    "hd_labels = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=100).fit_predict(raw_pendigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pendigits_raw_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_labels, digits.target, raw_pendigits, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_labels, digits.target, raw_pendigits, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_labels, digits.target, raw_pendigits, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_labels, digits.target, raw_pendigits, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_labels, digits.target, raw_pendigits, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "pendigits_raw_results_long = pendigits_raw_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "pendigits_raw_results_long[\"Dim Reduction\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c29edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pendigits_raw_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pendigits = PCA(n_components=16).fit_transform(raw_pendigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_pca_labels = cluster.KMeans(n_clusters=10).fit_predict(pca_pendigits)\n",
    "cl_pca_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(pca_pendigits)\n",
    "sl_pca_labels = cluster.AgglomerativeClustering(n_clusters=160, linkage=\"single\").fit_predict(pca_pendigits)\n",
    "db_pca_labels = cluster.DBSCAN(eps=15.0).fit_predict(pca_pendigits)\n",
    "hd_pca_labels = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=100).fit_predict(pca_pendigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac69dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pendigits_pca_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_pca_labels, digits.target, raw_pendigits, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_pca_labels, digits.target, raw_pendigits, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_pca_labels, digits.target, raw_pendigits, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_pca_labels, digits.target, raw_pendigits, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_pca_labels, digits.target, raw_pendigits, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "pendigits_pca_results_long = pendigits_pca_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "pendigits_pca_results_long[\"Dim Reduction\"] = \"PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([pendigits_raw_results_long, pendigits_pca_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed13ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_pendigits = umap.UMAP(n_components=4, min_dist=1e-8, random_state=0).fit_transform(raw_pendigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_umap_labels = cluster.KMeans(n_clusters=10).fit_predict(umap_pendigits)\n",
    "cl_umap_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(umap_pendigits)\n",
    "sl_umap_labels = cluster.AgglomerativeClustering(n_clusters=20, linkage=\"single\").fit_predict(umap_pendigits)\n",
    "db_umap_labels = cluster.DBSCAN(eps=0.5).fit_predict(umap_pendigits)\n",
    "hd_umap_labels = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=100).fit_predict(umap_pendigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb953751",
   "metadata": {},
   "outputs": [],
   "source": [
    "pendigits_umap_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_umap_labels, digits.target, raw_pendigits, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_umap_labels, digits.target, raw_pendigits, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_umap_labels, digits.target, raw_pendigits, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_umap_labels, digits.target, raw_pendigits, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_umap_labels, digits.target, raw_pendigits, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "pendigits_umap_results_long = pendigits_umap_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "pendigits_umap_results_long[\"Dim Reduction\"] = \"UMAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([pendigits_raw_results_long, pendigits_pca_results_long, pendigits_umap_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([pendigits_raw_results_long, pendigits_pca_results_long, pendigits_umap_results_long]), \n",
    "            score_types=(\"ARI\", \"AMI\", \"Silhouette\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ff1bf",
   "metadata": {},
   "source": [
    "# COIL-20 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5137d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_coil = coil_20_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a847aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_labels = cluster.KMeans(n_clusters=20).fit_predict(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c76dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cl_labels = cluster.AgglomerativeClustering(n_clusters=20, linkage=\"complete\").fit_predict(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sl_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db_labels = cluster.DBSCAN(eps=5000.0).fit_predict(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05861c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(db_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3073e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hd_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coil_raw_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_labels, coil_20_target, raw_coil, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_labels, coil_20_target, raw_coil, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_labels, coil_20_target, raw_coil, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_labels, coil_20_target, raw_coil, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_labels, coil_20_target, raw_coil, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "coil_raw_results_long = coil_raw_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "coil_raw_results_long[\"Dim Reduction\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(coil_raw_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6091bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coil = PCA(n_components=64).fit_transform(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_pca_labels = cluster.KMeans(n_clusters=20).fit_predict(pca_coil)\n",
    "cl_pca_labels = cluster.AgglomerativeClustering(n_clusters=20, linkage=\"complete\").fit_predict(pca_coil)\n",
    "sl_pca_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(pca_coil)\n",
    "db_pca_labels = cluster.DBSCAN(eps=4000.0).fit_predict(pca_coil)\n",
    "hd_pca_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(pca_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a697ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "coil_pca_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_pca_labels, coil_20_target, raw_coil, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_pca_labels, coil_20_target, raw_coil, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_pca_labels, coil_20_target, raw_coil, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_pca_labels, coil_20_target, raw_coil, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_pca_labels, coil_20_target, raw_coil, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "coil_pca_results_long = coil_pca_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "coil_pca_results_long[\"Dim Reduction\"] = \"PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10708ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([coil_raw_results_long, coil_pca_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db259a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_coil = umap.UMAP(n_neighbors=5, n_components=4, min_dist=1e-8, random_state=0, n_epochs=1000).fit_transform(raw_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721dcf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_umap_labels = cluster.KMeans(n_clusters=20).fit_predict(umap_coil)\n",
    "cl_umap_labels = cluster.AgglomerativeClustering(n_clusters=20, linkage=\"complete\").fit_predict(umap_coil)\n",
    "sl_umap_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(umap_coil)\n",
    "db_umap_labels = cluster.DBSCAN(eps=0.3).fit_predict(umap_coil)\n",
    "hd_umap_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(umap_coil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e31e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coil_umap_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_umap_labels, coil_20_target, raw_coil, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_umap_labels, coil_20_target, raw_coil, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_umap_labels, coil_20_target, raw_coil, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_umap_labels, coil_20_target, raw_coil, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_umap_labels, coil_20_target, raw_coil, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "coil_umap_results_long = coil_umap_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "coil_umap_results_long[\"Dim Reduction\"] = \"UMAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8270f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([coil_raw_results_long, coil_pca_results_long, coil_umap_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(\n",
    "    pd.concat([coil_raw_results_long, coil_pca_results_long, coil_umap_results_long]),\n",
    "    score_types=(\"ARI\", \"AMI\", \"Silhouette\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632ada2",
   "metadata": {},
   "source": [
    "# MNIST Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mnist = mnist.data.astype(np.float32)[:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9379e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_labels = cluster.KMeans(n_clusters=10).fit_predict(raw_mnist)\n",
    "cl_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(raw_mnist)\n",
    "sl_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(raw_mnist)\n",
    "db_labels = cluster.DBSCAN(eps=1000.0).fit_predict(raw_mnist)\n",
    "hd_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(raw_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_raw_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_labels, mnist.target[:35000], raw_mnist, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_labels, mnist.target[:35000], raw_mnist, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_labels, mnist.target[:35000], raw_mnist, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "mnist_raw_results_long = mnist_raw_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "mnist_raw_results_long[\"Dim Reduction\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(mnist_raw_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40775f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mnist = PCA(n_components=32).fit_transform(raw_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_pca_labels = cluster.KMeans(n_clusters=10).fit_predict(pca_mnist)\n",
    "cl_pca_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(pca_mnist)\n",
    "sl_pca_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(pca_mnist)\n",
    "db_pca_labels = cluster.DBSCAN(eps=600.0).fit_predict(pca_mnist)\n",
    "hd_pca_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(pca_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pca_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_pca_labels, mnist.target[:35000], raw_mnist, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_pca_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_pca_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_pca_labels, mnist.target[:35000], raw_mnist, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_pca_labels, mnist.target[:35000], raw_mnist, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "mnist_pca_results_long = mnist_pca_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "mnist_pca_results_long[\"Dim Reduction\"] = \"PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5959d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([mnist_raw_results_long, mnist_pca_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_mnist = umap.UMAP(n_neighbors=10, n_components=4, min_dist=1e-8, random_state=42, n_epochs=500).fit_transform(raw_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534eda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_umap_labels = cluster.KMeans(n_clusters=10).fit_predict(umap_mnist)\n",
    "cl_umap_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(umap_mnist)\n",
    "sl_umap_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(umap_mnist)\n",
    "db_umap_labels = cluster.DBSCAN(eps=0.1).fit_predict(umap_mnist)\n",
    "hd_umap_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(umap_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c49ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_umap_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_umap_labels, mnist.target[:35000], raw_mnist, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_umap_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_umap_labels, mnist.target[:35000], raw_mnist, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_umap_labels, mnist.target[:35000], raw_mnist, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_umap_labels, mnist.target[:35000], raw_mnist, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "mnist_umap_results_long = mnist_umap_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "mnist_umap_results_long[\"Dim Reduction\"] = \"UMAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([mnist_raw_results_long, mnist_pca_results_long, mnist_umap_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e330b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(\n",
    "    pd.concat([mnist_raw_results_long, mnist_pca_results_long, mnist_umap_results_long]),\n",
    "    score_types=(\"ARI\", \"AMI\", \"Silhouette\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8049f97",
   "metadata": {},
   "source": [
    "# USPS Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_usps = usps.data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_labels = cluster.KMeans(n_clusters=10).fit_predict(raw_usps)\n",
    "cl_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(raw_usps)\n",
    "sl_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(raw_usps)\n",
    "db_labels = cluster.DBSCAN(eps=3.5).fit_predict(raw_usps)\n",
    "hd_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(raw_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60de117",
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_raw_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_labels, usps.target, raw_usps, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_labels, usps.target, raw_usps, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_labels, usps.target, raw_usps, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_labels, usps.target, raw_usps, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_labels, usps.target, raw_usps, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "usps_raw_results_long = usps_raw_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "usps_raw_results_long[\"Dim Reduction\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(usps_raw_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_usps = PCA(n_components=32).fit_transform(raw_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf99d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_pca_labels = cluster.KMeans(n_clusters=10).fit_predict(pca_usps)\n",
    "cl_pca_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(pca_usps)\n",
    "sl_pca_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(pca_usps)\n",
    "db_pca_labels = cluster.DBSCAN(eps=2.0).fit_predict(pca_usps)\n",
    "hd_pca_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(pca_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ac8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_pca_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_pca_labels, usps.target, raw_usps, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_pca_labels, usps.target, raw_usps, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_pca_labels, usps.target, raw_usps, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_pca_labels, usps.target, raw_usps, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_pca_labels, usps.target, raw_usps, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "usps_pca_results_long = usps_pca_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "usps_pca_results_long[\"Dim Reduction\"] = \"PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([usps_raw_results_long, usps_pca_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_usps = umap.UMAP(n_neighbors=10, n_components=4, min_dist=1e-8, random_state=42, n_epochs=500).fit_transform(raw_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_umap_labels = cluster.KMeans(n_clusters=10).fit_predict(umap_usps)\n",
    "cl_umap_labels = cluster.AgglomerativeClustering(n_clusters=10, linkage=\"complete\").fit_predict(umap_usps)\n",
    "sl_umap_labels = cluster.AgglomerativeClustering(n_clusters=80, linkage=\"single\").fit_predict(umap_usps)\n",
    "db_umap_labels = cluster.DBSCAN(eps=0.15).fit_predict(umap_usps)\n",
    "hd_umap_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=100).fit_predict(umap_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee60d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "usps_umap_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_umap_labels, usps.target, raw_usps, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_umap_labels, usps.target, raw_usps, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_umap_labels, usps.target, raw_usps, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_umap_labels, usps.target, raw_usps, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_umap_labels, usps.target, raw_usps, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "usps_umap_results_long = usps_umap_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "usps_umap_results_long[\"Dim Reduction\"] = \"UMAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([usps_raw_results_long, usps_pca_results_long, usps_umap_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(\n",
    "    pd.concat([usps_raw_results_long, usps_pca_results_long, usps_umap_results_long]),\n",
    "    score_types=(\"ARI\", \"AMI\", \"Silhouette\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4cc14",
   "metadata": {},
   "source": [
    "# Buildings Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaa48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_buildings = buildings_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_labels = cluster.KMeans(n_clusters=40).fit_predict(raw_buildings)\n",
    "cl_labels = cluster.AgglomerativeClustering(n_clusters=40, linkage=\"complete\").fit_predict(raw_buildings)\n",
    "sl_labels = cluster.AgglomerativeClustering(n_clusters=120, linkage=\"single\").fit_predict(raw_buildings)\n",
    "db_labels = cluster.DBSCAN(eps=6000).fit_predict(raw_buildings)\n",
    "hd_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(raw_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd610b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_raw_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_labels, buildings_target, raw_buildings, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_labels, buildings_target, raw_buildings, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_labels, buildings_target, raw_buildings, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_labels, buildings_target, raw_buildings, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_labels, buildings_target, raw_buildings, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "buildings_raw_results_long = buildings_raw_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "buildings_raw_results_long[\"Dim Reduction\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046176ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(buildings_raw_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4853d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_buildings = PCA(n_components=32).fit_transform(raw_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_pca_labels = cluster.KMeans(n_clusters=40).fit_predict(pca_buildings)\n",
    "cl_pca_labels = cluster.AgglomerativeClustering(n_clusters=40, linkage=\"complete\").fit_predict(pca_buildings)\n",
    "sl_pca_labels = cluster.AgglomerativeClustering(n_clusters=120, linkage=\"single\").fit_predict(pca_buildings)\n",
    "db_pca_labels = cluster.DBSCAN(eps=2000.0).fit_predict(pca_buildings)\n",
    "hd_pca_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(pca_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_pca_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_pca_labels, buildings_target, raw_buildings, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_pca_labels, buildings_target, raw_buildings, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_pca_labels, buildings_target, raw_buildings, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_pca_labels, buildings_target, raw_buildings, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_pca_labels, buildings_target, raw_buildings, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "buildings_pca_results_long = buildings_pca_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "buildings_pca_results_long[\"Dim Reduction\"] = \"PCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([buildings_raw_results_long, buildings_pca_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_buildings = umap.UMAP(n_neighbors=8, n_components=4, min_dist=1e-8, random_state=42, n_epochs=1000).fit_transform(raw_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf445f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "km_umap_labels = cluster.KMeans(n_clusters=40).fit_predict(umap_buildings)\n",
    "cl_umap_labels = cluster.AgglomerativeClustering(n_clusters=40, linkage=\"complete\").fit_predict(umap_buildings)\n",
    "sl_umap_labels = cluster.AgglomerativeClustering(n_clusters=120, linkage=\"single\").fit_predict(umap_buildings)\n",
    "db_umap_labels = cluster.DBSCAN(eps=0.25).fit_predict(umap_buildings)\n",
    "hd_umap_labels = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=20).fit_predict(umap_buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43de324",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_umap_results = pd.DataFrame(\n",
    "    [\n",
    "        eval_clusters(km_umap_labels, buildings_target, raw_buildings, cluster_method=\"K-Means\"),\n",
    "        eval_clusters(cl_umap_labels, buildings_target, raw_buildings, cluster_method=\"Complete\\nLinkage\"),\n",
    "        eval_clusters(sl_umap_labels, buildings_target, raw_buildings, cluster_method=\"Single\\nLinkage\"),\n",
    "        eval_clusters(db_umap_labels, buildings_target, raw_buildings, cluster_method=\"DBSCAN\"),\n",
    "        eval_clusters(hd_umap_labels, buildings_target, raw_buildings, cluster_method=\"HDBSCAN\"),\n",
    "    ]\n",
    ")\n",
    "buildings_umap_results_long = buildings_umap_results.melt([\"Method\", \"Pct Clustered\"], var_name=\"Score Type\", value_name=\"Score\")\n",
    "buildings_umap_results_long[\"Dim Reduction\"] = \"UMAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db15559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(pd.concat([buildings_raw_results_long, buildings_pca_results_long, buildings_umap_results_long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ea48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(\n",
    "    pd.concat([buildings_raw_results_long, buildings_pca_results_long, buildings_umap_results_long]),\n",
    "    score_types=(\"ARI\", \"AMI\", \"Silhouette\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ba3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HighDimensionalClustering",
   "language": "python",
   "name": "highdimensionalclustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
